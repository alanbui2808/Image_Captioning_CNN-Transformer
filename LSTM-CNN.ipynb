{"cells":[{"cell_type":"markdown","metadata":{"id":"Y-zg9v2F01ES"},"source":["Python Environment"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RcZJtN4GQTwA","executionInfo":{"status":"ok","timestamp":1648952971571,"user_tz":240,"elapsed":14921,"user":{"displayName":"Prahlad Das","userId":"05551689746018416150"}},"outputId":"3cd3edd9-83d6-4dab-e677-dc6dc5919673"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T1ZDB2wB0eJq","outputId":"e963f5ca-588a-43f3-dba8-49190664a376","executionInfo":{"status":"ok","timestamp":1648952980826,"user_tz":240,"elapsed":4243,"user":{"displayName":"Prahlad Das","userId":"05551689746018416150"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensorflow: 2.8.0\n","keras: 2.8.0\n"]}],"source":["# tensorflow version\n","import tensorflow\n","print('tensorflow: %s' % tensorflow.__version__)\n","# keras version\n","import keras\n","print('keras: %s' % keras.__version__)"]},{"cell_type":"markdown","metadata":{"id":"6DSJtSKS1NLt"},"source":["Prepare photo"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"xPVo9G_w03e1","executionInfo":{"status":"ok","timestamp":1648952983202,"user_tz":240,"elapsed":153,"user":{"displayName":"Prahlad Das","userId":"05551689746018416150"}}},"outputs":[],"source":["# extract features from each photo in the directory\n","def extract_features(directory):\n","\t# load the model\n","\tmodel = VGG16()\n","\t# re-structure the model\n","\tmodel = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n","\t# summarize\n","\tprint(model.summary())\n","\t# extract features from each photo\n","\tfeatures = dict()\n","\tfor name in listdir(directory):\n","\t\t# load an image from file\n","\t\tfilename = directory + '/' + name\n","\t\timage = load_img(filename, target_size=(224, 224))\n","\t\t# convert the image pixels to a numpy array\n","\t\timage = img_to_array(image)\n","\t\t# reshape data for the model\n","\t\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","\t\t# prepare the image for the VGG model\n","\t\timage = preprocess_input(image)\n","\t\t# get features\n","\t\tfeature = model.predict(image, verbose=0)\n","\t\t# get image id\n","\t\timage_id = name.split('.')[0]\n","\t\t# store feature\n","\t\tfeatures[image_id] = feature\n","\t\tprint('>%s' % name)\n","\treturn features"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"xYW_lwmR1OmU","outputId":"38cf5567-3b69-4490-c944-515acf6cf8f4","executionInfo":{"status":"error","timestamp":1648953054424,"user_tz":240,"elapsed":24711,"user":{"displayName":"Prahlad Das","userId":"05551689746018416150"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n","553467904/553467096 [==============================] - 3s 0us/step\n","553476096/553467096 [==============================] - 3s 0us/step\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 25088)             0         \n","                                                                 \n"," fc1 (Dense)                 (None, 4096)              102764544 \n","                                                                 \n"," fc2 (Dense)                 (None, 4096)              16781312  \n","                                                                 \n","=================================================================\n","Total params: 134,260,544\n","Trainable params: 134,260,544\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]},{"output_type":"error","ename":"IsADirectoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-43f94ac3877c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# extract features from all images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/682_Project/Flickr8k_Dataset'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Extracted Features: %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# save to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-43f94ac3877c>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0;31m# load an image from file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0;31m# convert the image pixels to a numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    312\u001b[0m   \"\"\"\n\u001b[1;32m    313\u001b[0m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0;32m--> 314\u001b[0;31m                         target_size=target_size, interpolation=interpolation)\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/content/drive/MyDrive/682_Project/Flickr8k_Dataset/Flicker8k_Dataset'"]}],"source":["from os import listdir\n","from pickle import dump\n","from keras.applications.vgg16 import VGG16\n","from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","from keras.applications.vgg16 import preprocess_input\n","from keras.models import Model\n","\n","# extract features from each photo in the directory\n","def extract_features(directory):\n","\t# load the model\n","\tmodel = VGG16()\n","\t# re-structure the model\n","\tmodel = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n","\t# summarize\n","\tprint(model.summary())\n","\t# extract features from each photo\n","\tfeatures = dict()\n","\tfor name in listdir(directory):\n","\t\t# load an image from file\n","\t\tfilename = directory + '/' + name\n","\t\timage = load_img(filename, target_size=(224, 224))\n","\t\t# convert the image pixels to a numpy array\n","\t\timage = img_to_array(image)\n","\t\t# reshape data for the model\n","\t\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","\t\t# prepare the image for the VGG model\n","\t\timage = preprocess_input(image)\n","\t\t# get features\n","\t\tfeature = model.predict(image, verbose=0)\n","\t\t# get image id\n","\t\timage_id = name.split('.')[0]\n","\t\t# store feature\n","\t\tfeatures[image_id] = feature\n","\t\tprint('>%s' % name)\n","\treturn features\n","\n","# extract features from all images\n","directory = '/content/drive/MyDrive/682_Project/Flickr8k_Dataset'\n","features = extract_features(directory)\n","print('Extracted Features: %d' % len(features))\n","# save to file\n","dump(features, open('features.pkl', 'wb'))"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"LSTM-CNN.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}